"""
IFSå¨èƒè¯„ä¼°ç³»ç»Ÿæµ‹è¯•è„šæœ¬

åŒ…å«å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ï¼ŒéªŒè¯ç³»ç»Ÿçš„æ­£ç¡®æ€§å’Œæ€§èƒ½
"""

import sys
import os
import time
import json
import numpy as np

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ifs_core import IFS, IFSConverter, IFSOperations
from threat_indicators import ThreatIndicators
from threat_evaluator import IFSThreatEvaluator
from terrain_analyzer import TerrainAnalyzer
from visualizer import ThreatVisualizer


class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.test_results = []
    
    def assert_equal(self, actual, expected, test_name: str):
        """æ–­è¨€ç›¸ç­‰"""
        if actual == expected:
            self.passed += 1
            print(f"  âœ“ {test_name}")
            return True
        else:
            self.failed += 1
            print(f"  âœ— {test_name}: Expected {expected}, got {actual}")
            return False
    
    def assert_true(self, condition, test_name: str):
        """æ–­è¨€ä¸ºçœŸ"""
        if condition:
            self.passed += 1
            print(f"  âœ“ {test_name}")
            return True
        else:
            self.failed += 1
            print(f"  âœ— {test_name}: Condition is False")
            return False
    
    def assert_range(self, value, min_val, max_val, test_name: str):
        """æ–­è¨€åœ¨èŒƒå›´å†…"""
        if min_val <= value <= max_val:
            self.passed += 1
            print(f"  âœ“ {test_name}")
            return True
        else:
            self.failed += 1
            print(f"  âœ— {test_name}: {value} not in range [{min_val}, {max_val}]")
            return False
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        total = self.passed + self.failed
        success_rate = (self.passed / total * 100) if total > 0 else 0
        
        print("\n" + "=" * 80)
        print("æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        print(f"æ€»æµ‹è¯•æ•°: {total}")
        print(f"é€šè¿‡: {self.passed} ({success_rate:.1f}%)")
        print(f"å¤±è´¥: {self.failed}")
        print("=" * 80)


def test_ifs_core():
    """æµ‹è¯•IFSæ ¸å¿ƒåº“"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—1ã€‘æµ‹è¯• IFS æ ¸å¿ƒåº“")
    print("=" * 80)
    
    runner = TestRunner()
    
    # æµ‹è¯•1ï¼šIFSåŸºæœ¬åˆ›å»º
    print("\næµ‹è¯•1.1ï¼šIFSåŸºæœ¬åˆ›å»ºå’Œçº¦æŸ")
    ifs1 = IFS(0.7, 0.2)
    runner.assert_range(ifs1.mu, 0, 1, "éš¶å±åº¦åœ¨[0,1]èŒƒå›´å†…")
    runner.assert_range(ifs1.nu, 0, 1, "ééš¶å±åº¦åœ¨[0,1]èŒƒå›´å†…")
    runner.assert_range(ifs1.pi, 0, 1, "çŠ¹è±«åº¦åœ¨[0,1]èŒƒå›´å†…")
    runner.assert_true(abs((ifs1.mu + ifs1.nu + ifs1.pi) - 1.0) < 0.001, 
                      "Î¼ + Î½ + Ï€ = 1")
    
    # æµ‹è¯•2ï¼šå¾—åˆ†å‡½æ•°
    print("\næµ‹è¯•1.2ï¼šå¾—åˆ†å‡½æ•°å’Œç²¾ç¡®å‡½æ•°")
    score = ifs1.score()
    runner.assert_range(score, -1, 1, "å¾—åˆ†å‡½æ•°åœ¨[-1,1]èŒƒå›´å†…")
    accuracy = ifs1.accuracy()
    runner.assert_range(accuracy, 0, 1, "ç²¾ç¡®å‡½æ•°åœ¨[0,1]èŒƒå›´å†…")
    
    # æµ‹è¯•3ï¼šæ•°æ®è½¬æ¢
    print("\næµ‹è¯•1.3ï¼šæ•°æ®ç±»å‹è½¬æ¢")
    converter = IFSConverter()
    
    # å®æ•°è½¬æ¢
    ifs_real = converter.from_real_number(30, ideal=0, tolerance=15, min_val=0, max_val=50)
    runner.assert_true(isinstance(ifs_real, IFS), "å®æ•°è½¬IFSæˆåŠŸ")
    
    # è¯­è¨€æœ¯è¯­è½¬æ¢
    ifs_high = converter.from_linguistic_term('é«˜')
    ifs_low = converter.from_linguistic_term('ä½')
    runner.assert_true(ifs_high.score() > ifs_low.score(), "é«˜å¨èƒ > ä½å¨èƒ")
    
    # æµ‹è¯•4ï¼šIFSè¿ç®—
    print("\næµ‹è¯•1.4ï¼šIFSè¿ç®—")
    ops = IFSOperations()
    
    # æ¯”è¾ƒ
    comparison = ops.compare(ifs_high, ifs_low)
    runner.assert_equal(comparison, 1, "é«˜å¨èƒIFS > ä½å¨èƒIFS")
    
    # åŠ æƒå¹³å‡
    ifs_list = [IFS(0.8, 0.1), IFS(0.6, 0.3), IFS(0.4, 0.5)]
    weights = [0.5, 0.3, 0.2]
    ifs_avg = ops.weighted_average(ifs_list, weights)
    runner.assert_true(isinstance(ifs_avg, IFS), "åŠ æƒå¹³å‡è®¡ç®—æˆåŠŸ")
    
    runner.print_summary()
    return runner


def test_threat_indicators():
    """æµ‹è¯•å¨èƒæŒ‡æ ‡"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—2ã€‘æµ‹è¯•å¨èƒæŒ‡æ ‡é‡åŒ–")
    print("=" * 80)
    
    runner = TestRunner()
    indicators = ThreatIndicators()
    
    # æµ‹è¯•1ï¼šè·ç¦»æŒ‡æ ‡
    print("\næµ‹è¯•2.1ï¼šè·ç¦»æŒ‡æ ‡")
    dist_result_near = indicators.evaluate_distance(5)  # è¿‘è·ç¦»
    dist_result_far = indicators.evaluate_distance(40)  # è¿œè·ç¦»
    runner.assert_true(dist_result_near['threat_score'] > dist_result_far['threat_score'],
                      "è¿‘è·ç¦»å¨èƒ > è¿œè·ç¦»å¨èƒ")
    runner.assert_equal(dist_result_near['zone'], 'critical', "5ç±³ä¸ºæé«˜å¨èƒåŒºåŸŸ")
    
    # æµ‹è¯•2ï¼šé€Ÿåº¦æŒ‡æ ‡
    print("\næµ‹è¯•2.2ï¼šé€Ÿåº¦æŒ‡æ ‡")
    speed_high = indicators.evaluate_speed(8, 'soldier')
    speed_low = indicators.evaluate_speed(1, 'soldier')
    runner.assert_true(speed_high['threat_score'] > speed_low['threat_score'],
                      "é«˜é€Ÿå¨èƒ > ä½é€Ÿå¨èƒ")
    
    # æµ‹è¯•3ï¼šæ”»å‡»è§’åº¦
    print("\næµ‹è¯•2.3ï¼šæ”»å‡»è§’åº¦")
    angle_front = indicators.evaluate_attack_angle(
        enemy_direction=180,  # æœå‘ç©å®¶
        enemy_pos=(20, 0),
        player_pos=(0, 0)
    )
    angle_back = indicators.evaluate_attack_angle(
        enemy_direction=0,  # èƒŒå‘ç©å®¶
        enemy_pos=(20, 0),
        player_pos=(0, 0)
    )
    runner.assert_true(angle_front['threat_score'] > angle_back['threat_score'],
                      "æ­£é¢æ¥è¿‘å¨èƒ > èƒŒå‘æ’¤é€€å¨èƒ")
    
    # æµ‹è¯•4ï¼šç›®æ ‡ç±»å‹
    print("\næµ‹è¯•2.4ï¼šç›®æ ‡ç±»å‹")
    type_ifv = indicators.evaluate_target_type('ifv')
    type_soldier = indicators.evaluate_target_type('soldier')
    runner.assert_true(type_ifv['threat_score'] >= type_soldier['threat_score'],
                      "IFVå¨èƒ >= å£«å…µå¨èƒ")
    
    # æµ‹è¯•5ï¼šé€šè§†æ¡ä»¶
    print("\næµ‹è¯•2.5ï¼šé€šè§†æ¡ä»¶")
    vis_clear = indicators.evaluate_visibility(is_blocked=False, visibility_ratio=1.0)
    vis_blocked = indicators.evaluate_visibility(is_blocked=True, visibility_ratio=0.2)
    runner.assert_true(vis_clear['threat_score'] > vis_blocked['threat_score'],
                      "æ— é®æŒ¡å¨èƒ > æœ‰é®æŒ¡å¨èƒ")
    
    # æµ‹è¯•6ï¼šä½œæˆ˜ç¯å¢ƒ
    print("\næµ‹è¯•2.6ï¼šä½œæˆ˜ç¯å¢ƒ")
    env_open = indicators.evaluate_environment(0.1, 0.1)
    env_complex = indicators.evaluate_environment(0.8, 0.7)
    runner.assert_true(env_open['threat_score'] > env_complex['threat_score'],
                      "å¼€é˜”ç¯å¢ƒå¨èƒ > å¤æ‚ç¯å¢ƒå¨èƒ")
    
    runner.print_summary()
    return runner


def test_threat_evaluator():
    """æµ‹è¯•ç»¼åˆå¨èƒè¯„ä¼°å™¨"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—3ã€‘æµ‹è¯•ç»¼åˆå¨èƒè¯„ä¼°å™¨")
    print("=" * 80)
    
    runner = TestRunner()
    evaluator = IFSThreatEvaluator()
    
    # åˆ›å»ºæµ‹è¯•æ•Œäºº
    enemies = [
        {
            'id': 1,
            'type': 'ifv',
            'x': 15.0,
            'z': 10.0,
            'speed': 12.0,
            'direction': 200  # æœå‘ç©å®¶
        },
        {
            'id': 2,
            'type': 'soldier',
            'x': 40.0,
            'z': 30.0,
            'speed': 2.0,
            'direction': 90  # ä¾§å‘
        },
        {
            'id': 3,
            'type': 'soldier',
            'x': 8.0,
            'z': 5.0,
            'speed': 7.0,
            'direction': 180  # æ¥è¿‘
        }
    ]
    
    # æµ‹è¯•1ï¼šå•ç›®æ ‡è¯„ä¼°
    print("\næµ‹è¯•3.1ï¼šå•ç›®æ ‡è¯„ä¼°")
    result = evaluator.evaluate_single_target(enemies[0])
    runner.assert_true('comprehensive_threat_score' in result, "åŒ…å«ç»¼åˆå¨èƒå¾—åˆ†")
    runner.assert_true('threat_level' in result, "åŒ…å«å¨èƒç­‰çº§")
    runner.assert_true('indicator_details' in result, "åŒ…å«æŒ‡æ ‡è¯¦æƒ…")
    runner.assert_range(result['comprehensive_threat_score'], -1, 1, "ç»¼åˆå¾—åˆ†åœ¨[-1,1]èŒƒå›´å†…")
    runner.assert_true(result['evaluation_time'] > 0, "è¯„ä¼°è€—æ—¶å·²è®°å½•")
    
    # æµ‹è¯•2ï¼šå¤šç›®æ ‡æ’åº
    print("\næµ‹è¯•3.2ï¼šå¤šç›®æ ‡å¨èƒæ’åº")
    ranked = evaluator.rank_targets(enemies)
    runner.assert_equal(len(ranked), len(enemies), "æ’åºç»“æœæ•°é‡æ­£ç¡®")
    runner.assert_true(ranked[0]['rank'] == 1, "ç¬¬ä¸€årank=1")
    
    # éªŒè¯æ’åºæ­£ç¡®æ€§
    scores = [r['comprehensive_threat_score'] for r in ranked]
    is_sorted = all(scores[i] >= scores[i+1] for i in range(len(scores)-1))
    runner.assert_true(is_sorted, "å¨èƒåº¦æŒ‰é™åºæ’åˆ—")
    
    # æµ‹è¯•3ï¼šæ‰¾å‡ºæœ€é«˜å¨èƒ
    print("\næµ‹è¯•3.3ï¼šå¿«é€Ÿè¯†åˆ«æœ€é«˜å¨èƒ")
    most_threatening = evaluator.find_most_threatening(enemies)
    runner.assert_true(most_threatening is not None, "æ‰¾åˆ°æœ€é«˜å¨èƒç›®æ ‡")
    runner.assert_true(most_threatening['enemy_id'] == ranked[0]['enemy_id'],
                      "æœ€é«˜å¨èƒä¸æ’åºç¬¬ä¸€åä¸€è‡´")
    
    # æµ‹è¯•4ï¼šç›®æ ‡å¯¹æ¯”
    print("\næµ‹è¯•3.4ï¼šç›®æ ‡å¯¹æ¯”")
    comparison = evaluator.compare_targets(enemies[0], enemies[1])
    runner.assert_true('more_threatening' in comparison, "åŒ…å«å¯¹æ¯”ç»“æœ")
    runner.assert_true('score_difference' in comparison, "åŒ…å«å¾—åˆ†å·®å¼‚")
    
    # æµ‹è¯•5ï¼šç»Ÿè®¡ä¿¡æ¯
    print("\næµ‹è¯•3.5ï¼šå¨èƒç»Ÿè®¡")
    stats = evaluator.get_threat_statistics(ranked)
    runner.assert_equal(stats['total_enemies'], len(enemies), "æ€»æ•Œäººæ•°æ­£ç¡®")
    runner.assert_true('threat_level_distribution' in stats, "åŒ…å«å¨èƒç­‰çº§åˆ†å¸ƒ")
    runner.assert_true('score_statistics' in stats, "åŒ…å«å¾—åˆ†ç»Ÿè®¡")
    
    runner.print_summary()
    return runner


def test_terrain_analyzer():
    """æµ‹è¯•åœ°å½¢åˆ†æå™¨"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—4ã€‘æµ‹è¯•åœ°å½¢åˆ†æå™¨")
    print("=" * 80)
    
    runner = TestRunner()
    analyzer = TerrainAnalyzer()
    
    # è®¾ç½®æµ‹è¯•åœ°å½¢
    analyzer.buildings = [
        {'id': 1, 'x': 10, 'z': 10, 'width': 8, 'depth': 8, 'height': 10}
    ]
    analyzer.obstacles = [
        {'id': 1, 'type': 'Cover', 'x': 20, 'z': 20, 'width': 2, 'depth': 2}
    ]
    
    # æµ‹è¯•1ï¼šé€šè§†æ£€æµ‹
    print("\næµ‹è¯•4.1ï¼šé€šè§†æ¡ä»¶æ£€æµ‹")
    vis_blocked = analyzer.check_line_of_sight((0, 0), (10, 10))  # ç©¿è¿‡å»ºç­‘
    vis_clear = analyzer.check_line_of_sight((0, 0), (50, 50))   # å¼€é˜”åŒºåŸŸ
    
    runner.assert_true(vis_blocked['is_blocked'], "æ£€æµ‹åˆ°å»ºç­‘é®æŒ¡")
    runner.assert_true(not vis_clear['is_blocked'], "å¼€é˜”åŒºåŸŸæ— é®æŒ¡")
    
    # æµ‹è¯•2ï¼šç¯å¢ƒå¤æ‚åº¦
    print("\næµ‹è¯•4.2ï¼šç¯å¢ƒå¤æ‚åº¦è®¡ç®—")
    env_near_building = analyzer.calculate_environment_complexity((10, 10), radius=5)
    env_open_area = analyzer.calculate_environment_complexity((50, 50), radius=10)
    
    runner.assert_true(env_near_building['nearby_buildings'] > 0, "å»ºç­‘é™„è¿‘æ£€æµ‹åˆ°å»ºç­‘ç‰©")
    runner.assert_equal(env_open_area['nearby_buildings'], 0, "å¼€é˜”åŒºåŸŸæ— å»ºç­‘ç‰©")
    runner.assert_true(env_near_building['complexity_level'] in ['open', 'moderate', 'complex'],
                      "å¤æ‚åº¦ç­‰çº§æœ‰æ•ˆ")
    
    # æµ‹è¯•3ï¼šæˆ˜æœ¯ä½ç½®åˆ†æ
    print("\næµ‹è¯•4.3ï¼šæˆ˜æœ¯ä½ç½®ç»¼åˆåˆ†æ")
    tactical = analyzer.analyze_tactical_position((15, 15), player_pos=(0, 0))
    runner.assert_true('visibility' in tactical, "åŒ…å«é€šè§†ä¿¡æ¯")
    runner.assert_true('environment' in tactical, "åŒ…å«ç¯å¢ƒä¿¡æ¯")
    runner.assert_true('tactical_advantage' in tactical, "åŒ…å«æˆ˜æœ¯ä¼˜åŠ¿è¯„ä¼°")
    
    runner.print_summary()
    return runner


def test_performance():
    """æ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—5ã€‘æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 80)
    
    evaluator = IFSThreatEvaluator()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    num_enemies = 30
    enemies = []
    for i in range(num_enemies):
        angle = np.random.uniform(0, 2*np.pi)
        distance = np.random.uniform(10, 40)
        enemies.append({
            'id': i+1,
            'type': np.random.choice(['soldier', 'ifv']),
            'x': distance * np.cos(angle),
            'z': distance * np.sin(angle),
            'speed': np.random.uniform(1, 15),
            'direction': np.random.uniform(0, 360)
        })
    
    # æµ‹è¯•1ï¼šå•ç›®æ ‡è¯„ä¼°æ€§èƒ½
    print(f"\næµ‹è¯•5.1ï¼šå•ç›®æ ‡è¯„ä¼°æ€§èƒ½ï¼ˆ{num_enemies}æ¬¡ï¼‰")
    times = []
    for enemy in enemies:
        start = time.time()
        evaluator.evaluate_single_target(enemy)
        times.append((time.time() - start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    avg_time = np.mean(times)
    max_time = np.max(times)
    print(f"  å¹³å‡è€—æ—¶: {avg_time:.2f}ms")
    print(f"  æœ€å¤§è€—æ—¶: {max_time:.2f}ms")
    print(f"  âœ“ ç›®æ ‡: < 5ms, å®é™…: {avg_time:.2f}ms {'[é€šè¿‡]' if avg_time < 5 else '[è¶…æ—¶]'}")
    
    # æµ‹è¯•2ï¼šå¤šç›®æ ‡æ’åºæ€§èƒ½
    print(f"\næµ‹è¯•5.2ï¼šå¤šç›®æ ‡æ’åºæ€§èƒ½ï¼ˆ{num_enemies}ä¸ªç›®æ ‡ï¼‰")
    start = time.time()
    ranked = evaluator.rank_targets(enemies)
    elapsed = (time.time() - start) * 1000
    
    print(f"  æ’åºè€—æ—¶: {elapsed:.2f}ms")
    print(f"  âœ“ ç›®æ ‡: < 50ms, å®é™…: {elapsed:.2f}ms {'[é€šè¿‡]' if elapsed < 50 else '[è¶…æ—¶]'}")
    
    # æµ‹è¯•3ï¼šæ‰¾æœ€é«˜å¨èƒæ€§èƒ½
    print(f"\næµ‹è¯•5.3ï¼šæ‰¾æœ€é«˜å¨èƒæ€§èƒ½ï¼ˆ{num_enemies}ä¸ªç›®æ ‡ï¼‰")
    start = time.time()
    most_threatening = evaluator.find_most_threatening(enemies)
    elapsed = (time.time() - start) * 1000
    
    print(f"  æŸ¥æ‰¾è€—æ—¶: {elapsed:.2f}ms")
    print(f"  âœ“ ç›®æ ‡: < 50ms, å®é™…: {elapsed:.2f}ms {'[é€šè¿‡]' if elapsed < 50 else '[è¶…æ—¶]'}")


def test_integration():
    """é›†æˆæµ‹è¯•ï¼šå®Œæ•´æµç¨‹"""
    print("\n" + "=" * 80)
    print("ã€æ¨¡å—6ã€‘é›†æˆæµ‹è¯• - å®Œæ•´è¯„ä¼°æµç¨‹")
    print("=" * 80)
    
    # åˆ›å»ºæ‰€æœ‰ç»„ä»¶
    evaluator = IFSThreatEvaluator()
    visualizer = ThreatVisualizer(output_dir="examples")
    
    # æ¨¡æ‹Ÿæˆ˜åœºåœºæ™¯
    print("\nåœºæ™¯ï¼šåŸå¸‚å··æˆ˜ï¼Œç©å®¶è¢«3ä¸ªæ•ŒäººåŒ…å›´")
    enemies = [
        {
            'id': 1,
            'type': 'ifv',
            'x': 12.0,
            'z': 8.0,
            'speed': 10.0,
            'direction': 225  # è¥¿å—æ–¹å‘ï¼Œæ¥è¿‘ç©å®¶
        },
        {
            'id': 2,
            'type': 'soldier',
            'x': -15.0,
            'z': 10.0,
            'speed': 5.0,
            'direction': 45   # ä¸œåŒ—æ–¹å‘ï¼Œæ¥è¿‘ç©å®¶
        },
        {
            'id': 3,
            'type': 'soldier',
            'x': 5.0,
            'z': -20.0,
            'speed': 2.0,
            'direction': 90   # ä¸œï¼Œä¾§å‘ç§»åŠ¨
        }
    ]
    
    # æ‰§è¡Œå¨èƒè¯„ä¼°
    print("\næ‰§è¡Œå¨èƒè¯„ä¼°...")
    ranked_results = evaluator.rank_targets(enemies)
    
    # æ˜¾ç¤ºç»“æœ
    print("\nå¨èƒè¯„ä¼°ç»“æœï¼š")
    for result in ranked_results:
        print(f"\n  [{result['rank']}] æ•Œäºº#{result['enemy_id']} "
              f"({result['indicator_details']['type']['type_name']})")
        print(f"      ç»¼åˆå¨èƒå¾—åˆ†: {result['comprehensive_threat_score']:.3f}")
        print(f"      å¨èƒç­‰çº§: {result['threat_level']}")
        print(f"      è·ç¦»: {result['distance']:.1f}m")
        print(f"      å…³é”®æŒ‡æ ‡:")
        for ind_name, ind_data in result['indicator_details'].items():
            if 'threat_score' in ind_data:
                print(f"        - {ind_name}: {ind_data['threat_score']:.3f}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    try:
        # å¨èƒæ’å
        ranking_file = visualizer.plot_threat_ranking(ranked_results, "integration_ranking.png")
        print(f"  âœ“ å¨èƒæ’å: {ranking_file}")
        
        # é›·è¾¾å›¾ï¼ˆæœ€é«˜å¨èƒï¼‰
        radar_file = visualizer.plot_radar_chart(ranked_results[0], "integration_radar.png")
        print(f"  âœ“ å¨èƒé›·è¾¾å›¾: {radar_file}")
        
        # è´¡çŒ®åº¦åˆ†æ
        contrib_file = visualizer.plot_indicator_contributions(
            ranked_results[0], "integration_contributions.png"
        )
        print(f"  âœ“ æŒ‡æ ‡è´¡çŒ®åº¦: {contrib_file}")
        
        # å¯¹æ¯”åˆ†æ
        compare_file = visualizer.plot_comparison(ranked_results, "integration_comparison.png")
        print(f"  âœ“ ç›®æ ‡å¯¹æ¯”: {compare_file}")
        
    except Exception as e:
        print(f"  âš  å¯è§†åŒ–ç”Ÿæˆè­¦å‘Š: {e}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = evaluator.get_threat_statistics(ranked_results)
    
    print("\n\næˆ˜åœºæ€åŠ¿ç»Ÿè®¡ï¼š")
    print(f"  æ€»æ•Œäººæ•°: {stats['total_enemies']}")
    print(f"  å¨èƒç­‰çº§åˆ†å¸ƒ: {stats['threat_level_distribution']}")
    print(f"  å¹³å‡å¨èƒå¾—åˆ†: {stats['score_statistics']['mean']:.3f}")
    print(f"  å¾—åˆ†èŒƒå›´: [{stats['score_statistics']['min']:.3f}, "
          f"{stats['score_statistics']['max']:.3f}]")
    
    print("\nâœ“ é›†æˆæµ‹è¯•å®Œæˆ")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("IFSå¨èƒè¯„ä¼°ç³»ç»Ÿ - å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("=" * 80)
    print("åŸºäºè®ºæ–‡ï¼šã€Šåœ°é¢ä½œæˆ˜ç›®æ ‡å¨èƒè¯„ä¼°å¤šå±æ€§æŒ‡æ ‡å¤„ç†æ–¹æ³•ã€‹")
    print("=" * 80)
    
    all_runners = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    try:
        all_runners.append(test_ifs_core())
        all_runners.append(test_threat_indicators())
        all_runners.append(test_threat_evaluator())
        all_runners.append(test_terrain_analyzer())
        test_performance()
        test_integration()
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    # æ€»ä½“æµ‹è¯•æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("æ€»ä½“æµ‹è¯•æŠ¥å‘Š")
    print("=" * 80)
    
    total_passed = sum(r.passed for r in all_runners)
    total_failed = sum(r.failed for r in all_runners)
    total_tests = total_passed + total_failed
    
    if total_tests > 0:
        success_rate = total_passed / total_tests * 100
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡: {total_passed} ({success_rate:.1f}%)")
        print(f"å¤±è´¥: {total_failed}")
        
        if total_failed == 0:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        else:
            print(f"\nâš ï¸  æœ‰ {total_failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ã€‚")
    
    print("=" * 80)


if __name__ == "__main__":
    main()

